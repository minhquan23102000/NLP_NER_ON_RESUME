{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_PATH = ['../CV/CV2', '../CV/Technical', '../CV/HR', '../CV/Marketing', '../CV/Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz\n",
    "import pyvi\n",
    "import nltk\n",
    "import langdetect\n",
    "import langid\n",
    "\n",
    "def extract_text_from_pdf(filename):\n",
    "    pdf = fitz.open(filename)\n",
    "    cv_text = \"\"\n",
    "    \n",
    "    for page in pdf:\n",
    "        cv_text += page.get_text() + \" \"\n",
    "        \n",
    "    return cv_text\n",
    "    \n",
    "\n",
    "def clean_whitespace(statement):\n",
    "    \"\"\"\n",
    "    Remove any consecutive whitespace characters from the statement text.\n",
    "    \"\"\"\n",
    "\n",
    "    import re \n",
    "    \n",
    "    # Replace linebreaks and tabs with spaces\n",
    "    statement = ' '.join(statement.split())\n",
    "\n",
    "    # Remove any leading or trailing whitespace\n",
    "    statement = statement.strip()\n",
    "\n",
    "    # Remove consecutive spaces\n",
    "    statement = re.sub(' +', ' ', statement)\n",
    "\n",
    "    return statement\n",
    "\n",
    "def clean_text(text):\n",
    "    import re \n",
    "    from pyvi import ViUtils\n",
    "    text = re.sub(r\"[^'/\\\\&@.+#*%\\w\\d\\s]\", ' ', text)\n",
    "    #remove accents\n",
    "    text = ViUtils.remove_accents(text).decode('utf-8')\n",
    "    \n",
    "    text = clean_whitespace(text)\n",
    "    \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asd @ m__mm 123+. C# C++ ASP.NET zxczx @#@'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text('asd-@ m__mm\\t123+.~~~~ C# C++ ASP.NET zxczx~@#@!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESUME \n",
      "NGUYEN NGOC TRUC \n",
      " \n",
      "A. \n",
      "PERSONAL DATA \n",
      "         Hand phone:  \n",
      "+8493 771 2575 \n",
      "         Email address  \n",
      "truc.nguyen1704@gmail.com  \n",
      "B. \n",
      "EDUCATION \n",
      " \n",
      "2003 – 2007 \n",
      "BA Degree in Literature & Journ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = extract_text_from_pdf('../CV/CV2/COE01-Product Director - Nguyễn Ngọc Trú1.pdf')\n",
    "print(text[:200])\n",
    "langdetect.detect(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('en', -9228.376918792725)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langid.classify(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read pdf convert to txt file for training data design\n",
    "import random\n",
    "import re\n",
    "SAVE_PATH = '../data/CV_text'\n",
    "pdf_token = re.compile('^.+.pdf$')\n",
    "for cv_path in CV_PATH:\n",
    "    label = cv_path.split('/')[-1]\n",
    "    list_path = os.listdir(cv_path)\n",
    "    random.shuffle(list_path)\n",
    "    num_cv = 0\n",
    "    for index, file_name in enumerate(list_path):\n",
    "        if pdf_token.findall(file_name):\n",
    "            file_name = f\"{cv_path}/{file_name}\"\n",
    "            pdf_text = extract_text_from_pdf(file_name)\n",
    "        \n",
    "            if pdf_text == None:\n",
    "                continue\n",
    "            if langid.classify(pdf_text)[0] != 'en':\n",
    "                continue\n",
    "            \n",
    "            if len(pdf_text) > 4500:\n",
    "                continue\n",
    "            \n",
    "            for idx, sentence in enumerate(nltk.sent_tokenize(pdf_text)):\n",
    "                with open(f'{SAVE_PATH}/cv_{label}_{num_cv}_{idx}.txt', 'w', encoding='utf-8') as f:\n",
    "                    sentence = clean_text(sentence)\n",
    "                    f.write(sentence)\n",
    "            \n",
    "        if num_cv == 5:\n",
    "            break\n",
    "            \n",
    "        \n",
    "        num_cv +=1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read pdf convert to txt file for training data design\n",
    "import random\n",
    "import re\n",
    "SAVE_PATH = '../data/CV_text'\n",
    "pdf_token = re.compile('^.+.pdf$')\n",
    "CV_PATH = os.listdir('../CV/IT')\n",
    "for cv_path in CV_PATH:\n",
    "    label = cv_path.split('/')[-1]\n",
    "    path = f\"../CV/IT/{cv_path}\"\n",
    "    \n",
    "    if not os.path.isdir(path):\n",
    "        continue\n",
    "    \n",
    "    list_path = os.listdir(path)\n",
    "    random.shuffle(list_path)\n",
    "    num_cv = 0\n",
    "    for index, file_name in enumerate(list_path):\n",
    "        if pdf_token.findall(file_name):\n",
    "            file_name = f\"{path}/{file_name}\"\n",
    "            pdf_text = extract_text_from_pdf(file_name)\n",
    "        \n",
    "            if pdf_text == None:\n",
    "                continue\n",
    "            if langid.classify(pdf_text)[0] != 'en':\n",
    "                continue\n",
    "            \n",
    "            for idx, sentence in enumerate(nltk.sent_tokenize(pdf_text)):\n",
    "                with open(f'{SAVE_PATH}/cv_{label}_{num_cv}_{idx}.txt', 'w', encoding='utf-8') as f:\n",
    "                    sentence = clean_text(sentence)\n",
    "                    f.write(sentence)\n",
    "            \n",
    "        if num_cv == 5:\n",
    "            break\n",
    "            \n",
    "        \n",
    "        num_cv +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74aeec88d2a643caab20b24cbf533fb04c6ed7e57fd82ff5d9db5b72fd010c6a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('cv_parser')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
